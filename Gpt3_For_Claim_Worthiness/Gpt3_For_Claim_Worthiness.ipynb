{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    #sys.path.insert(0, \"..\")\n",
    "    sys.path.append('../')\n",
    "import os\n",
    "from io import StringIO\n",
    "import openai\n",
    "import wandb\n",
    "from openai.wandb_logger import WandbLogger\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import env_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = env_config.openai_api_key\n",
    "openai.api_key = env_config.openai_api_key\n",
    "\n",
    "project='Gpt3_For_ClaimWorthiness'\n",
    "entity=\"cemulu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt parameters\n",
    "# https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb\n",
    "suffix_separator = \"\\n\\n###\\n\\n\"\n",
    "# https://help.openai.com/en/articles/5072263-how-do-i-use-stop-sequences\n",
    "# https://beta.openai.com/docs/api-reference/completions\n",
    "stop_sequence = \"<|endoftext|>\" # 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_config(data_type: str):\n",
    "    suffix_separator = \"\"\n",
    "    stop_sequence = \"\"\n",
    "    negative_label = \"\"\n",
    "    positive_label = \"\"\n",
    "    training_file = \"\"\n",
    "    validation_file = \"\"\n",
    "    test_file = \"\"\n",
    "    data_type_name = data_type\n",
    "    if data_type == 'verbal':\n",
    "        suffix_separator = \"\\n\\n###\\n\\n\"\n",
    "        stop_sequence = \"<|endoftext|>\"\n",
    "        negative_label = ' no'\n",
    "        positive_label = ' yes'\n",
    "        training_file = \"file-4ohSE50WHT6I2OPU8dY0Nw4v\"\n",
    "        validation_file = \"file-viyeZCBdsAj2jcwa1Gax6Yqt\"\n",
    "        test_file = \"file-adHnzZJARCZGujo9UyMtVD7i\"\n",
    "    elif data_type == 'numeric':\n",
    "        suffix_separator = \"-->\"\n",
    "        stop_sequence = \"\"\n",
    "        negative_label = ' 0'\n",
    "        positive_label = ' 1'\n",
    "        training_file = \"file-K3FBozB8ixcE6W5mhtmkVbfV\"\n",
    "        validation_file = \"file-l7afntFWxFcBfgntmERBsUgF\"\n",
    "        test_file = \"file-6gcekJPZUxQdxv4OgAkDzVpa\"\n",
    "    data_config = {}\n",
    "    for variable in [\"suffix_separator\", \"stop_sequence\", \"negative_label\", \"positive_label\", \"training_file\", \"validation_file\", \"test_file\", \"data_type_name\"]:\n",
    "        data_config[variable] = eval(variable)\n",
    "    return data_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format and Load data to OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "data_dir = os.path.join(parent_dir, \"Data\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir,\"train_english_cleaned_without_mentions.tsv\"), delimiter='\\t')\n",
    "test_df = pd.read_csv(os.path.join(data_dir,\"test_english_cleaned_without_mentions.tsv\"), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_sequence(df, config):\n",
    "    df['completion'] = np.where(df['check_worthiness']==0, config['negative_label'], config['positive_label'])\n",
    "    df['completion'] = df['completion'].astype(str) + config['stop_sequence']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix_separator(df, config):\n",
    "    df['prompt'] = df['tweet_text'].astype(str) + config['suffix_separator']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propmtify_and_save(df: pd.DataFrame, file_name: str, config:dict):\n",
    "    df = add_suffix_separator(df, config)\n",
    "    df = add_stop_sequence(df, config)\n",
    "    df = df[['prompt', 'completion']]\n",
    "    file_path = os.path.join(parent_dir, 'Data', file_name+\"_\"+config['data_type_name']+'.tsv')\n",
    "    df.to_csv(file_path, sep='\\t', encoding='utf-8', index=False)\n",
    "    !openai tools fine_tunes.prepare_data -f $file_path -q\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = get_data_config('verbal')\n",
    "propmtify_and_save(train_df, 'prompts_train',data_config)\n",
    "propmtify_and_save(test_df, 'prompts_test', data_config)\n",
    "\n",
    "data_config = get_data_config('numeric')\n",
    "propmtify_and_save(train_df, 'prompts_train',data_config)\n",
    "propmtify_and_save(test_df, 'prompts_test', data_config)\n",
    "\n",
    "# after this step name of the files changed manually. \"_prepared\" suffix removed from file names. Test files combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_openai(file_name):\n",
    "    file_path = os.path.join(parent_dir, 'Data', file_name)\n",
    "    with open(file_path, encoding=\"utf8\") as json_file:\n",
    "        response = openai.File.create(file=json_file, purpose='fine-tune')\n",
    "        print('File id:')\n",
    "        print(response.id)\n",
    "        return response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_openai('prompts_numeric_test.jsonl')\n",
    "load_data_to_openai('prompts_numeric_valid.jsonl')\n",
    "load_data_to_openai('prompts_numeric_train.jsonl')\n",
    "\n",
    "load_data_to_openai('prompts_verbal_test.jsonl')\n",
    "load_data_to_openai('prompts_verbal_valid.jsonl')\n",
    "load_data_to_openai('prompts_verbal_train.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File id:\n",
    "file-6gcekJPZUxQdxv4OgAkDzVpa\n",
    "\n",
    "File id:\n",
    "file-l7afntFWxFcBfgntmERBsUgF\n",
    "\n",
    "File id:\n",
    "file-K3FBozB8ixcE6W5mhtmkVbfV\n",
    "\n",
    "File id:\n",
    "file-adHnzZJARCZGujo9UyMtVD7i\n",
    "\n",
    "File id:\n",
    "file-viyeZCBdsAj2jcwa1Gax6Yqt\n",
    "\n",
    "File id:\n",
    "file-4ohSE50WHT6I2OPU8dY0Nw4v\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tune GPT3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\" : \"GPT_finetune\",\n",
    "    \"method\" : \"bayes\",\n",
    "    'metric': {\n",
    "      'name': 'classification/auroc',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        'data_version': {\n",
    "          'values': ['verbal', 'numeric'],\n",
    "          'distribution': 'categorical'  \n",
    "        },\n",
    "        \"n_epochs\" : {\n",
    "          \"min\": 2,\n",
    "          \"max\": 10,\n",
    "           'distribution': 'int_uniform'\n",
    "        },\n",
    "        \"batch_size\" : {\n",
    "          \"min\": 2,\n",
    "          \"max\": 64,\n",
    "           'distribution': 'int_uniform'\n",
    "        },\n",
    "        \"learning_rate_multiplier\" :{\n",
    "          \"min\": 0.005,\n",
    "          \"max\": 0.4\n",
    "        },\n",
    "        \"prompt_loss_weight\" :{\n",
    "          \"min\": 0.005,\n",
    "          \"max\": 0.4\n",
    "        },\n",
    "        \"model\" : {\n",
    "          \"values\": [\"ada\", \"babbage\", \"curie\"]\n",
    "        }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_defaults = {\n",
    "        'data_version': 'verbal',\n",
    "        \"n_epochs\" : 4,\n",
    "        \"batch_size\" : 3,\n",
    "        \"learning_rate_multiplier\" : 0.09114315140152794,\n",
    "        \"prompt_loss_weight\" : 0.05197519625234356,\n",
    "        \"model\" : \"ada\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project=project)\n",
    "sweep_id = 'yfhhwgoo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    run = wandb.init(config=sweep_defaults)\n",
    "    config = wandb.config\n",
    "    # print(config)\n",
    "    data_config = get_data_config(config.data_version)\n",
    "    # print(data_config)\n",
    "    create_args = {\n",
    "        \"training_file\": data_config['training_file'],\n",
    "        \"validation_file\": data_config['validation_file'],\n",
    "        \"model\": config.model,\n",
    "        \"compute_classification_metrics\": True,\n",
    "        \"classification_n_classes\": 2,\n",
    "        \"n_epochs\" : config.n_epochs,\n",
    "        \"batch_size\" : config.batch_size,\n",
    "        \"learning_rate_multiplier\" :config.learning_rate_multiplier,\n",
    "        \"prompt_loss_weight\" :config.prompt_loss_weight,\n",
    "        \"classification_positive_class\" : data_config['positive_label']+data_config['stop_sequence']\n",
    "    }\n",
    "    # print('***')\n",
    "    # print(create_args)\n",
    "    create_response = openai.FineTune.create(**create_args)\n",
    "    finetune_id = create_response.id\n",
    "    print(f'Finetune request created. Finetune id: {finetune_id}')\n",
    "\n",
    "    event_counter = 0\n",
    "    while True:\n",
    "        response = openai.FineTune.retrieve(id=finetune_id)\n",
    "        status = response.status\n",
    "        print(f'Status: {status}')\n",
    "        \n",
    "        if status == \"succeeded\":\n",
    "            WandbLogger.sync(\n",
    "                id=finetune_id,\n",
    "                n_fine_tunes=None,\n",
    "                project=project,\n",
    "                entity=None,\n",
    "                force=False,\n",
    "            )\n",
    "            run.finish()\n",
    "            return\n",
    "        elif status == \"failed\":\n",
    "            print(f'Finetune job {finetune_id} finished with status: {status}')\n",
    "            return\n",
    "        else:\n",
    "            events = response.events\n",
    "            if len(events)>event_counter:\n",
    "                print(events[event_counter:len(events)])\n",
    "                event_counter=len(events)\n",
    "            time.sleep(20)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, project=project, function=train, count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Verbal GPT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose2binary(verbose_answer):\n",
    "    binary_label = -1\n",
    "    verbose_answer = verbose_answer.strip().lower()\n",
    "    if verbose_answer == 'yes':\n",
    "        binary_label = 1\n",
    "    elif verbose_answer == 'no':\n",
    "        binary_label = 0\n",
    "    else:\n",
    "        print(f\"Warning! Deviant! Output is => '{verbose_answer}'\")\n",
    "\n",
    "    return binary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_worthiness(tweet):\n",
    "    tweet = tweet + suffix_separator\n",
    "    result = openai.Completion.create(model = env_config.fine_tuned_model,\n",
    "    prompt=str(tweet), max_tokens=10, temperature=0,logprobs=5)['choices'][0]\n",
    "\n",
    "    verbose_answer = result['text']\n",
    "    probability = pd.DataFrame([result[\"logprobs\"][\"top_logprobs\"][0]]).T.apply(lambda x: np.e**x).max().item()\n",
    "\n",
    "    binary_label = verbose2binary(verbose_answer)\n",
    "\n",
    "    return binary_label, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(os.path.join(data_dir,\"eval_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "binary_label_list = []\n",
    "probability_list = []\n",
    "\n",
    "for index, row in eval_df.iterrows():\n",
    "    binary_label, probability = check_worthiness(row.tweet_text)\n",
    "    binary_label_list.append(binary_label)\n",
    "    probability_list.append(probability)\n",
    "    \n",
    "    if (index+1) % 50 == 0:\n",
    "        print (str(index))\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>check_worthiness</th>\n",
       "      <th>bert_predictions</th>\n",
       "      <th>bert_probability</th>\n",
       "      <th>roberta_predictions</th>\n",
       "      <th>roberta_probability</th>\n",
       "      <th>bertweet_predictions</th>\n",
       "      <th>bertweet_probability</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>gpt3_predictions</th>\n",
       "      <th>gpt3_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237160250513522688</td>\n",
       "      <td>https://twitter.com/user/status/12371602505135...</td>\n",
       "      <td>POTUS wanted everyone to know he was in close ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988866</td>\n",
       "      <td>[0.16674243, 0.3065092, -0.112421855, 0.048177...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237125962871037953</td>\n",
       "      <td>https://twitter.com/user/status/12371259628710...</td>\n",
       "      <td>Who would you prefer to lead our nation’s resp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>[0.22938012, 0.054673575, -0.0858, -0.07526214...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237207721604235264</td>\n",
       "      <td>https://twitter.com/user/status/12372077216042...</td>\n",
       "      <td>It was a really really really really really re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>[0.03409792, 0.45846257, -0.015111784, 0.25196...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1237178597024108552</td>\n",
       "      <td>https://twitter.com/user/status/12371785970241...</td>\n",
       "      <td>Bald-faced LIE. did self-quarantine until CDC ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990378</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990838</td>\n",
       "      <td>[0.008557552, -0.16238855, -0.34488454, 0.0608...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237049051058561024</td>\n",
       "      <td>https://twitter.com/user/status/12370490510585...</td>\n",
       "      <td>LIVE: Daily media briefing on COVID-19 with CO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>[-0.4223225, 0.272865, -0.1823175, -0.44944727...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                          tweet_url  \\\n",
       "0  1237160250513522688  https://twitter.com/user/status/12371602505135...   \n",
       "1  1237125962871037953  https://twitter.com/user/status/12371259628710...   \n",
       "2  1237207721604235264  https://twitter.com/user/status/12372077216042...   \n",
       "3  1237178597024108552  https://twitter.com/user/status/12371785970241...   \n",
       "4  1237049051058561024  https://twitter.com/user/status/12370490510585...   \n",
       "\n",
       "                                          tweet_text  check_worthiness  \\\n",
       "0  POTUS wanted everyone to know he was in close ...                 1   \n",
       "1  Who would you prefer to lead our nation’s resp...                 0   \n",
       "2  It was a really really really really really re...                 0   \n",
       "3  Bald-faced LIE. did self-quarantine until CDC ...                 1   \n",
       "4  LIVE: Daily media briefing on COVID-19 with CO...                 0   \n",
       "\n",
       "   bert_predictions  bert_probability  roberta_predictions  \\\n",
       "0                 1          0.993853                    1   \n",
       "1                 0          0.000108                    0   \n",
       "2                 0          0.000569                    0   \n",
       "3                 1          0.999796                    1   \n",
       "4                 0          0.000080                    0   \n",
       "\n",
       "   roberta_probability  bertweet_predictions  bertweet_probability  \\\n",
       "0             0.983054                     1              0.988866   \n",
       "1             0.006362                     0              0.006661   \n",
       "2             0.004905                     0              0.007607   \n",
       "3             0.990378                     1              0.990838   \n",
       "4             0.005420                     0              0.007499   \n",
       "\n",
       "                                          embeddings  gpt3_predictions  \\\n",
       "0  [0.16674243, 0.3065092, -0.112421855, 0.048177...                 1   \n",
       "1  [0.22938012, 0.054673575, -0.0858, -0.07526214...                 0   \n",
       "2  [0.03409792, 0.45846257, -0.015111784, 0.25196...                 0   \n",
       "3  [0.008557552, -0.16238855, -0.34488454, 0.0608...                 1   \n",
       "4  [-0.4223225, 0.272865, -0.1823175, -0.44944727...                 0   \n",
       "\n",
       "   gpt3_probability  \n",
       "0          0.890893  \n",
       "1          0.999922  \n",
       "2          0.959031  \n",
       "3          0.971630  \n",
       "4          0.999801  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df[\"gpt3_predictions\"] = binary_label_list\n",
    "eval_df[\"gpt3_probability\"] = probability_list\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = eval_df.columns.drop(['embeddings']).to_list() + ['embeddings']\n",
    "eval_df = eval_df[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(\"eval_df.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = '''Nancy Pelosi and Democrats \"want to turn 150 million Americans into felons overnight\" with HR 1808.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.9944344941322952)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_worthiness(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tweet + suffix_separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.Completion.create(model = env_config.fine_tuned_model,\n",
    "    prompt=prompt, max_tokens=10, temperature=0,logprobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if result.usage.completion_tokens > 1:\n",
    "    print(\"Alert!! Deviant:\" + result['choices'][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x20b6df27830> JSON: {\n",
       "  \" YES\": -9.917364,\n",
       "  \" Yes\": -10.518929,\n",
       "  \" no\": -5.219633,\n",
       "  \" yeah\": -10.79642,\n",
       "  \" yes\": -0.005581051\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['choices'][0].logprobs.top_logprobs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6fd66f23f291c7a70d0834aa3c84fb3d8a0e23845cff3812a1a92aee36ee1d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
