{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    #sys.path.insert(0, \"..\")\n",
    "    sys.path.append('../')\n",
    "import os\n",
    "from io import StringIO\n",
    "import openai\n",
    "import wandb\n",
    "from openai.wandb_logger import WandbLogger\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import env_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = env_config.openai_api_key\n",
    "openai.api_key = env_config.openai_api_key\n",
    "\n",
    "project='Gpt3_For_ClaimWorthiness'\n",
    "entity=\"cemulu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt parameters\n",
    "# https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb\n",
    "suffix_separator = \"\\n\\n###\\n\\n\"\n",
    "# https://help.openai.com/en/articles/5072263-how-do-i-use-stop-sequences\n",
    "# https://beta.openai.com/docs/api-reference/completions\n",
    "stop_sequence = \"<|endoftext|>\" # 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_config(data_type: str):\n",
    "    suffix_separator = \"\"\n",
    "    stop_sequence = \"\"\n",
    "    negative_label = \"\"\n",
    "    positive_label = \"\"\n",
    "    training_file = \"\"\n",
    "    validation_file = \"\"\n",
    "    test_file = \"\"\n",
    "    data_type_name = data_type\n",
    "    if data_type == 'verbal':\n",
    "        suffix_separator = \"\\n\\n###\\n\\n\"\n",
    "        stop_sequence = \"<|endoftext|>\"\n",
    "        negative_label = ' no'\n",
    "        positive_label = ' yes'\n",
    "        training_file = \"file-4ohSE50WHT6I2OPU8dY0Nw4v\"\n",
    "        validation_file = \"file-viyeZCBdsAj2jcwa1Gax6Yqt\"\n",
    "        test_file = \"file-adHnzZJARCZGujo9UyMtVD7i\"\n",
    "    elif data_type == 'numeric':\n",
    "        suffix_separator = \"-->\"\n",
    "        stop_sequence = \"\"\n",
    "        negative_label = ' 0'\n",
    "        positive_label = ' 1'\n",
    "        training_file = \"file-K3FBozB8ixcE6W5mhtmkVbfV\"\n",
    "        validation_file = \"file-l7afntFWxFcBfgntmERBsUgF\"\n",
    "        test_file = \"file-6gcekJPZUxQdxv4OgAkDzVpa\"\n",
    "    data_config = {}\n",
    "    for variable in [\"suffix_separator\", \"stop_sequence\", \"negative_label\", \"positive_label\", \"training_file\", \"validation_file\", \"test_file\", \"data_type_name\"]:\n",
    "        data_config[variable] = eval(variable)\n",
    "    return data_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format and Load data to OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "train_df = pd.read_csv(os.path.join(parent_dir, 'Data',\"train_english_cleaned_without_mentions.tsv\"), delimiter='\\t')\n",
    "test_df = pd.read_csv(os.path.join(parent_dir, 'Data',\"test_english_cleaned_without_mentions.tsv\"), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_sequence(df, config):\n",
    "    df['completion'] = np.where(df['check_worthiness']==0, config['negative_label'], config['positive_label'])\n",
    "    df['completion'] = df['completion'].astype(str) + config['stop_sequence']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix_separator(df, config):\n",
    "    df['prompt'] = df['tweet_text'].astype(str) + config['suffix_separator']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propmtify_and_save(df: pd.DataFrame, file_name: str, config:dict):\n",
    "    df = add_suffix_separator(df, config)\n",
    "    df = add_stop_sequence(df, config)\n",
    "    df = df[['prompt', 'completion']]\n",
    "    file_path = os.path.join(parent_dir, 'Data', file_name+\"_\"+config['data_type_name']+'.tsv')\n",
    "    df.to_csv(file_path, sep='\\t', encoding='utf-8', index=False)\n",
    "    !openai tools fine_tunes.prepare_data -f $file_path -q\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = get_data_config('verbal')\n",
    "propmtify_and_save(train_df, 'prompts_train',data_config)\n",
    "propmtify_and_save(test_df, 'prompts_test', data_config)\n",
    "\n",
    "data_config = get_data_config('numeric')\n",
    "propmtify_and_save(train_df, 'prompts_train',data_config)\n",
    "propmtify_and_save(test_df, 'prompts_test', data_config)\n",
    "\n",
    "# after this step name of the files changed manually. \"_prepared\" suffix removed from file names. Test files combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_openai(file_name):\n",
    "    file_path = os.path.join(parent_dir, 'Data', file_name)\n",
    "    with open(file_path, encoding=\"utf8\") as json_file:\n",
    "        response = openai.File.create(file=json_file, purpose='fine-tune')\n",
    "        print('File id:')\n",
    "        print(response.id)\n",
    "        return response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_openai('prompts_numeric_test.jsonl')\n",
    "load_data_to_openai('prompts_numeric_valid.jsonl')\n",
    "load_data_to_openai('prompts_numeric_train.jsonl')\n",
    "\n",
    "load_data_to_openai('prompts_verbal_test.jsonl')\n",
    "load_data_to_openai('prompts_verbal_valid.jsonl')\n",
    "load_data_to_openai('prompts_verbal_train.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File id:\n",
    "file-6gcekJPZUxQdxv4OgAkDzVpa\n",
    "\n",
    "File id:\n",
    "file-l7afntFWxFcBfgntmERBsUgF\n",
    "\n",
    "File id:\n",
    "file-K3FBozB8ixcE6W5mhtmkVbfV\n",
    "\n",
    "File id:\n",
    "file-adHnzZJARCZGujo9UyMtVD7i\n",
    "\n",
    "File id:\n",
    "file-viyeZCBdsAj2jcwa1Gax6Yqt\n",
    "\n",
    "File id:\n",
    "file-4ohSE50WHT6I2OPU8dY0Nw4v\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tune GPT3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\" : \"GPT_finetune\",\n",
    "    \"method\" : \"bayes\",\n",
    "    'metric': {\n",
    "      'name': 'classification/auroc',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        'data_version': {\n",
    "          'values': ['verbal', 'numeric'],\n",
    "          'distribution': 'categorical'  \n",
    "        },\n",
    "        \"n_epochs\" : {\n",
    "          \"min\": 2,\n",
    "          \"max\": 10,\n",
    "           'distribution': 'int_uniform'\n",
    "        },\n",
    "        \"batch_size\" : {\n",
    "          \"min\": 2,\n",
    "          \"max\": 64,\n",
    "           'distribution': 'int_uniform'\n",
    "        },\n",
    "        \"learning_rate_multiplier\" :{\n",
    "          \"min\": 0.005,\n",
    "          \"max\": 0.4\n",
    "        },\n",
    "        \"prompt_loss_weight\" :{\n",
    "          \"min\": 0.005,\n",
    "          \"max\": 0.4\n",
    "        },\n",
    "        \"model\" : {\n",
    "          \"values\": [\"ada\", \"babbage\", \"curie\"]\n",
    "        }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_defaults = {\n",
    "        'data_version': 'verbal',\n",
    "        \"n_epochs\" : 4,\n",
    "        \"batch_size\" : 3,\n",
    "        \"learning_rate_multiplier\" : 0.09114315140152794,\n",
    "        \"prompt_loss_weight\" : 0.05197519625234356,\n",
    "        \"model\" : \"ada\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project=project)\n",
    "sweep_id = 'yfhhwgoo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    run = wandb.init(config=sweep_defaults)\n",
    "    config = wandb.config\n",
    "    # print(config)\n",
    "    data_config = get_data_config(config.data_version)\n",
    "    # print(data_config)\n",
    "    create_args = {\n",
    "        \"training_file\": data_config['training_file'],\n",
    "        \"validation_file\": data_config['validation_file'],\n",
    "        \"model\": config.model,\n",
    "        \"compute_classification_metrics\": True,\n",
    "        \"classification_n_classes\": 2,\n",
    "        \"n_epochs\" : config.n_epochs,\n",
    "        \"batch_size\" : config.batch_size,\n",
    "        \"learning_rate_multiplier\" :config.learning_rate_multiplier,\n",
    "        \"prompt_loss_weight\" :config.prompt_loss_weight,\n",
    "        \"classification_positive_class\" : data_config['positive_label']+data_config['stop_sequence']\n",
    "    }\n",
    "    # print('***')\n",
    "    # print(create_args)\n",
    "    create_response = openai.FineTune.create(**create_args)\n",
    "    finetune_id = create_response.id\n",
    "    print(f'Finetune request created. Finetune id: {finetune_id}')\n",
    "\n",
    "    event_counter = 0\n",
    "    while True:\n",
    "        response = openai.FineTune.retrieve(id=finetune_id)\n",
    "        status = response.status\n",
    "        print(f'Status: {status}')\n",
    "        \n",
    "        if status == \"succeeded\":\n",
    "            WandbLogger.sync(\n",
    "                id=finetune_id,\n",
    "                n_fine_tunes=None,\n",
    "                project=project,\n",
    "                entity=None,\n",
    "                force=False,\n",
    "            )\n",
    "            run.finish()\n",
    "            return\n",
    "        elif status == \"failed\":\n",
    "            print(f'Finetune job {finetune_id} finished with status: {status}')\n",
    "            return\n",
    "        else:\n",
    "            events = response.events\n",
    "            if len(events)>event_counter:\n",
    "                print(events[event_counter:len(events)])\n",
    "                event_counter=len(events)\n",
    "            time.sleep(20)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, project=project, function=train, count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Verbal GPT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6fd66f23f291c7a70d0834aa3c84fb3d8a0e23845cff3812a1a92aee36ee1d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
